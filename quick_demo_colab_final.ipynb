{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp2JsCYjGYt6OFdD7xj+DO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47d4c19984e146c185089fe5ba867451": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_1fbe3e569def4c388ed67424a44a3583",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 1/1 \u001b[2m0:00:00 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mtrain_loss: 2.312 train_acc: 0.047\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">train_loss: 2.312 train_acc: 0.047</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "1fbe3e569def4c388ed67424a44a3583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a3607b1d634de4ae04ff78bc8d96c4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_eac509b4de9945be9cd61e88a4bd37b8",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 704/704 \u001b[2m0:01:22 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m8.45it/s\u001b[0m \u001b[3mv_num: 0.000 train_loss: 1.299    \u001b[0m\n                                                                                 \u001b[3mtrain_acc: 0.500                  \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 704/704 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:01:22 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">8.45it/s</span> <span style=\"font-style: italic\">v_num: 0.000 train_loss: 1.299    </span>\n                                                                                 <span style=\"font-style: italic\">train_acc: 0.500                  </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "eac509b4de9945be9cd61e88a4bd37b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e88161df772e427595861a5e1b8ec55e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_66effa98dc864a29a1574b9780a073f4",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 1/1 \u001b[2m0:00:00 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mtrain_loss: 2.309 train_acc: 0.094\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">train_loss: 2.309 train_acc: 0.094</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "66effa98dc864a29a1574b9780a073f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68b8c5ca662463d971f1f1221b73dfb": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_1b76a47f3bab4bea90d7e80555f9a612",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 3/3 \u001b[2m0:00:00 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m8.85it/s\u001b[0m \u001b[3mv_num: 1.000 train_loss: 2.285      \u001b[0m\n                                                                               \u001b[3mtrain_acc: 0.125                    \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 3/3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">8.85it/s</span> <span style=\"font-style: italic\">v_num: 1.000 train_loss: 2.285      </span>\n                                                                               <span style=\"font-style: italic\">train_acc: 0.125                    </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "1b76a47f3bab4bea90d7e80555f9a612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92cc99e211b94228bef5a3043c1777a3": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_df7476d7792a416e87049843fec16303",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "df7476d7792a416e87049843fec16303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abe8d78f09d54841a5a06a0166e8b615": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_74a1ec37add047a8b79e875c3788d371",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "74a1ec37add047a8b79e875c3788d371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad06c259e55e4cf8a5b170541c98d401": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_34cead0f85d844e7abd8933076654ada",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 1/1  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 50/50 \u001b[2m0:00:06 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m7.82it/s\u001b[0m \u001b[3mv_num: 2.000 train_loss: 1.585      \u001b[0m\n                                                                               \u001b[3mtrain_acc: 0.469 val_loss: 1.821    \u001b[0m\n                                                                               \u001b[3mval_acc: 0.362                      \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 1/1  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 50/50 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:06 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">7.82it/s</span> <span style=\"font-style: italic\">v_num: 2.000 train_loss: 1.585      </span>\n                                                                               <span style=\"font-style: italic\">train_acc: 0.469 val_loss: 1.821    </span>\n                                                                               <span style=\"font-style: italic\">val_acc: 0.362                      </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "34cead0f85d844e7abd8933076654ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girisiman/Pytorch-Meetup-Nepal-Demo/blob/main/quick_demo_colab_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö° PyTorch Lightning - Interactive Demo\n",
        "\n",
        "**Instructions:**\n",
        "*   Run each cell to see Lightning in action - no prior setup needed!\n",
        "\n",
        "**What you'll learn:**\n",
        "1. How Lightning organizes PyTorch code\n",
        "2. One-line hardware scaling (CPU ‚Üí GPU ‚Üí Multi-GPU)\n",
        "3. Automatic best practices (logging, checkpointing, early stopping)\n",
        "4. Debugging superpowers\n"
      ],
      "metadata": {
        "id": "B40RyJxJ7KBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Part 1: Setup & Installation"
      ],
      "metadata": {
        "id": "QhQLejJ_7qfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install (if needed)\n",
        "!pip install torch torchvision lightning matplotlib\n",
        "\n",
        "# Cell 2: Show data\n",
        "print(\"This is CIFAR-10 data we'll train on...\")\n",
        "# Shows images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlKG53eX6xYx",
        "outputId": "a154917e-c460-4a5d-cce8-9f521aec0ea1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.6.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.11)\n",
            "Downloading lightning-2.6.0-py3-none-any.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.6.0 lightning-utilities-0.15.2 pytorch-lightning-2.6.0 torchmetrics-1.8.2\n",
            "This is CIFAR-10 data we'll train on...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Imports"
      ],
      "metadata": {
        "id": "RfNGUl4C7vxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Core\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# TorchVision for datasets\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# System\n",
        "import time\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Lightning version: {pl.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pyMjHCl7t_f",
        "outputId": "78afc893-f592-41df-8e75-42b7c27fccb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All imports successful!\n",
            "PyTorch version: 2.9.0+cpu\n",
            "Lightning version: 2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Part 2: Explore CIFAR-10 Dataset\n",
        "\n",
        "We'll use the CIFAR-10 dataset: 60,000; 32x32 color images in 10 classes"
      ],
      "metadata": {
        "id": "dL8VwHWs76jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "JmPffrxQ750q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "print(\"üì• Loading CIFAR-10 dataset...\")\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v9aFJVi8HsI",
        "outputId": "e2defc3a-3e09-4276-8dd4-4e0c77ce27ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading CIFAR-10 dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:04<00:00, 38.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset statistics\n",
        "print(f\"‚úÖ Training samples: {len(trainset):,}\")\n",
        "print(f\"‚úÖ Test samples: {len(testset):,}\")\n",
        "\n",
        "# Class names\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "print(f\"‚úÖ Classes: {classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6vbIUge8J-u",
        "outputId": "9aad0e02-15dc-44a9-951c-2dfed9a1efe3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training samples: 50,000\n",
            "‚úÖ Test samples: 10,000\n",
            "‚úÖ Classes: ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some samples from the dataset\n",
        "\n",
        "def show_images(images, labels, n=4):\n",
        "    \"\"\"Display n images with their labels\"\"\"\n",
        "    fig, axes = plt.subplots(1, n, figsize=(15, 4))\n",
        "    for i in range(n):\n",
        "        # Unnormalize the image\n",
        "        img = images[i] / 2 + 0.5  # Scale from [-1, 1] to [0, 1]\n",
        "        axes[i].imshow(img.permute(1, 2, 0))  # CHW ‚Üí HWC\n",
        "        axes[i].set_title(f\"Label: {classes[labels[i]]}\")\n",
        "        axes[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oVlBSo2Z8MfX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of images\n",
        "trainloader = DataLoader(trainset, batch_size=8, shuffle=True)\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "print(\"üñºÔ∏è Sample images from CIFAR-10:\")\n",
        "show_images(images, labels, n=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "B40oi_ya8PXc",
        "outputId": "d1b2334f-abb6-4fc2-d861-c1a1aef48d2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñºÔ∏è Sample images from CIFAR-10:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèóÔ∏è Part 3: Create a LightningModule\n",
        "\n",
        "**Key Concept:** LightningModule organizes your PyTorch code into 6 logical sections:\n",
        "  1. Initialization (`__init__`)\n",
        "  2. Training loop (`training_step`)\n",
        "  3. Validation loop (`validation_step`)\n",
        "  4. Test loop (`test_step`)\n",
        "  5. Prediction loop (`predict_step`)\n",
        "  6. Optimizers (`configure_optimizers`)"
      ],
      "metadata": {
        "id": "T8n3AacO8Wb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, create a pure PyTorch model (no Lightning here!)\n",
        "# This is the model architecture you would write anyway\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"A simple CNN for CIFAR-10 classification - Pure PyTorch!\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # 3 input channels (RGB), 32 output\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Reduces spatial dimensions by half\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # After 2 pooling layers: 32x32 ‚Üí 16x16 ‚Üí 8x8\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10 classes\n",
        "\n",
        "        # Regularization\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass - define how data flows through the network\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Conv ‚Üí ReLU ‚Üí Pool\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Another conv block\n",
        "\n",
        "        x = torch.flatten(x, 1)  # Flatten for fully connected layers\n",
        "        x = F.relu(self.fc1(x))  # Fully connected with ReLU\n",
        "        x = self.dropout(x)      # Regularization\n",
        "        x = self.fc2(x)          # Output layer (no activation - softmax in loss)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "se_z9Mm-8R-7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our pure PyTorch model\n",
        "print(\"Testing pure PyTorch model...\")\n",
        "sample_input = torch.randn(4, 3, 32, 32)  # Batch of 4, 3 channels, 32x32 images\n",
        "model = SimpleCNN()\n",
        "output = model(sample_input)\n",
        "print(f\"Input shape: {sample_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meW0EF3I8q1H",
        "outputId": "c8fbfb28-8ba6-47f1-8890-46335d8320e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing pure PyTorch model...\n",
            "Input shape: torch.Size([4, 3, 32, 32])\n",
            "Output shape: torch.Size([4, 10])\n",
            "Model has 545,098 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now wrap it in a LightningModule\n",
        "**Magic happens here:** LightningModule takes your PyTorch model and adds training logic"
      ],
      "metadata": {
        "id": "bAF7U8DM8zKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitCIFAR(pl.LightningModule):\n",
        "    \"\"\"LightningModule that wraps our PyTorch model with training logic\"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=1e-3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Save hyperparameters (auto-logged!)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Use our pure PyTorch model - no changes needed!\n",
        "        self.model = SimpleCNN()\n",
        "\n",
        "        # Loss function\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Track metrics\n",
        "        from torchmetrics import Accuracy # Import Accuracy from torchmetrics\n",
        "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    # ========== 1. Forward Pass ==========\n",
        "    def forward(self, x):\n",
        "        \"\"\"Inference - same as PyTorch forward\"\"\"\n",
        "        return self.model(x)\n",
        "\n",
        "    # ========== 2. Training Step ==========\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"What happens in ONE training batch\"\"\"\n",
        "        x, y = batch\n",
        "\n",
        "        # Forward pass\n",
        "        y_hat = self(x)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "\n",
        "        # Compute accuracy\n",
        "        preds = torch.argmax(y_hat, dim=1)\n",
        "        self.train_acc(preds, y)\n",
        "\n",
        "        # Log everything - automatically sent to TensorBoard, etc.\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.log('train_acc', self.train_acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # ========== 3. Validation Step ==========\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"What happens in ONE validation batch\"\"\"\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "\n",
        "        # Compute accuracy\n",
        "        preds = torch.argmax(y_hat, dim=1)\n",
        "        self.val_acc(preds, y)\n",
        "\n",
        "        # Log validation metrics\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # ========== 4. Test Step ==========\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        \"\"\"What happens in ONE test batch\"\"\"\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "\n",
        "        # Compute test accuracy\n",
        "        preds = torch.argmax(y_hat, dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "        self.log('test_acc', acc)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    # ========== 5. Configure Optimizers ==========\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Define optimizers and learning rate schedulers\"\"\"\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
        "\n",
        "        # Add a learning rate scheduler\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': scheduler,\n",
        "            'monitor': 'val_loss'  # Which metric to monitor for scheduling\n",
        "        }\n",
        "\n",
        "print(\"LightningModule created!\")\n",
        "print(\"Notice: We separated the WHAT (model, loss) from the HOW (training loop)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2S15vG48tB_",
        "outputId": "298e8e8e-4787-4c2e-cac9-89746085ee71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightningModule created!\n",
            "Notice: We separated the WHAT (model, loss) from the HOW (training loop)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Part 4: Create a LightningDataModule\n",
        "\n",
        "**Key Concept:** DataModule organizes your data loading code for reproducibility"
      ],
      "metadata": {
        "id": "llSiA2Gw9FS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10DataModule(pl.LightningDataModule):\n",
        "    \"\"\"Handles all data loading and preprocessing for CIFAR-10\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size=64):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Download data - runs only once on 1 GPU\"\"\"\n",
        "        torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "        torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"Split data - runs on every GPU\"\"\"\n",
        "        if stage == 'fit' or stage is None:\n",
        "            # Load full training set\n",
        "            full_train = torchvision.datasets.CIFAR10(\n",
        "                root='./data', train=True, transform=self.transform\n",
        "            )\n",
        "            # Split into train/validation (45k/5k)\n",
        "            self.train_data, self.val_data = random_split(full_train, [45000, 5000])\n",
        "            print(f\"Train: {len(self.train_data):,} samples\")\n",
        "            print(f\"Validation: {len(self.val_data):,} samples\")\n",
        "\n",
        "        if stage == 'test' or stage is None:\n",
        "            # Test set\n",
        "            self.test_data = torchvision.datasets.CIFAR10(\n",
        "                root='./data', train=False, transform=self.transform\n",
        "            )\n",
        "            print(f\"Test: {len(self.test_data):,} samples\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_data, batch_size=self.batch_size,\n",
        "                         shuffle=True, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_data, batch_size=self.batch_size,\n",
        "                         shuffle=False, num_workers=2)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_data, batch_size=self.batch_size,\n",
        "                         shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "OfWXCzE18-lJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and setup our data module\n",
        "print(\"Creating DataModule...\")\n",
        "data_module = CIFAR10DataModule(batch_size=64)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "\n",
        "# Show data loader statistics\n",
        "print(f\"\\n DataLoader statistics:\")\n",
        "print(f\"Train batches: {len(data_module.train_dataloader()):,}\")\n",
        "print(f\"Val batches: {len(data_module.val_dataloader()):,}\")\n",
        "print(f\"Test batches: {len(data_module.test_dataloader()):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgkO4rBe9OWp",
        "outputId": "72b145ea-6002-4cc5-c857-1014555f4ce5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating DataModule...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            " DataLoader statistics:\n",
            "Train batches: 704\n",
            "Val batches: 79\n",
            "Test batches: 157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Part 5: The Trainer - Lightning's Superpower\n",
        "\n",
        "**This is where the magic happens!**  \n",
        "\n",
        "### The `Trainer` class automates everything you used to write manually:\n",
        "Training loop\n",
        "- Validation loop\n",
        "- Checkpointing\n",
        "- Logging\n",
        "- Multi-GPU training\n",
        "- Early stopping\n",
        "- And much more!"
      ],
      "metadata": {
        "id": "Qr0cCIDS9jUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our model\n",
        "model = LitCIFAR(learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "8O_78PlM9Srx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 1: Fast Development Run\n",
        "\n",
        "**Problem:** In PyTorch, you write the whole training loop before you can test if it works.  \n",
        "**Solution:** `fast_dev_run=True` runs 1 batch to verify everything works!"
      ],
      "metadata": {
        "id": "axgad_a_-Ias"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DEMO 1: Fast Development Run\")\n",
        "print(\"=\" * 50)\n",
        "trainer_dev = Trainer(\n",
        "    fast_dev_run=True,      # Runs only 1 batch\n",
        "    max_epochs=1,           # Just 1 epoch\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=True,\n",
        ")\n",
        "\n",
        "print(\"\\nRunning fast_dev_run (should take < 10 seconds)...\")\n",
        "trainer_dev.fit(model, data_module)\n",
        "\n",
        "print(\"\\n Success! Our pipeline works.\")\n",
        "print(\"   No need to write training loops just to test if code works!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552,
          "referenced_widgets": [
            "47d4c19984e146c185089fe5ba867451",
            "1fbe3e569def4c388ed67424a44a3583"
          ]
        },
        "id": "w816GQFA9wtT",
        "outputId": "c0c5bfa2-9da5-4f3f-ab5a-6096d8097dd2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEMO 1: Fast Development Run\n",
            "==================================================\n",
            "\n",
            "Running fast_dev_run (should take < 10 seconds)...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 545 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 545 K                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 10                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 545 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 545 K                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 10                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47d4c19984e146c185089fe5ba867451"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Success! Our pipeline works.\n",
            "   No need to write training loops just to test if code works!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 2: CPU Training (Baseline)\n"
      ],
      "metadata": {
        "id": "Rb33MgFH-YcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 2: CPU Training\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBtrzdOk_DLC",
        "outputId": "d72f9dfe-cd98-466a-adf3-d1e5675e0f19"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 2: CPU Training\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_cpu = Trainer(\n",
        "    accelerator='cpu',      # Force CPU\n",
        "    max_epochs=1,           # Just 1 epoch for demo\n",
        "    log_every_n_steps=20,   # Log every 20 batches\n",
        "    enable_progress_bar=True,\n",
        ")\n",
        "\n",
        "print(\"\\nTraining on CPU...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLInzrI_-S8N",
        "outputId": "7f686a53-5dbb-4ad5-d1da-af1fadc8823c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on CPU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run:\n",
        "trainer_cpu.fit(model, data_module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358,
          "referenced_widgets": [
            "e5a3607b1d634de4ae04ff78bc8d96c4",
            "eac509b4de9945be9cd61e88a4bd37b8"
          ]
        },
        "id": "aHYlCWly-jZf",
        "outputId": "4bc8bf09-6972-46f5-eaac-5bd6a843ed34"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 545 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 545 K                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 10                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 545 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 545 K                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 10                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5a3607b1d634de4ae04ff78bc8d96c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Same code runs on CPU with zero changes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y95va1gq-nI0",
        "outputId": "b8e0fcd5-6237-4f25-b461-61b33a805365"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Same code runs on CPU with zero changes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 3: GPU Training (Automatic Detection)"
      ],
      "metadata": {
        "id": "Y8U46mdD-7di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 3: GPU Training (Auto-detect)\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiXTPGe9-rIz",
        "outputId": "8cdd6cd8-ca08-410e-b2af-471a193f24e8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 3: GPU Training (Auto-detect)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what hardware is available\n",
        "print(f\"Hardware check:\")\n",
        "print(f\"   CPU cores: Available\")\n",
        "print(f\"   GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU count: {torch.cuda.device_count()}\")\n",
        "    print(f\"   GPU name: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKSxMxYx--x6",
        "outputId": "9ffeb668-3e16-484a-d6fa-447f8b81c911"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hardware check:\n",
            "   CPU cores: Available\n",
            "   GPU available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_gpu = Trainer(\n",
        "    accelerator='auto',     # Automatically picks GPU if available\n",
        "    devices='auto',         # Use all available devices\n",
        "    max_epochs=1,\n",
        "    log_every_n_steps=20,\n",
        "    enable_progress_bar=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjlT44rz_Kg9",
        "outputId": "8d2494de-c1e7-42ee-fbf5-130dd1285ccd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Key insight: Change 'cpu' to 'auto' to use GPU\")\n",
        "print(\"   No code changes in model or data!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSqK8vwo_NxV",
        "outputId": "c740408b-e1b5-4917-e6cc-b9f36110aebb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Key insight: Change 'cpu' to 'auto' to use GPU\n",
            "   No code changes in model or data!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run if GPU is available:\n",
        "if torch.cuda.is_available():\n",
        "  trainer_gpu.fit(model, data_module)\n",
        "else:\n",
        "  print(\"‚ö†Ô∏è  No GPU available, but code would work if there was!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HitJmXet_Q5X",
        "outputId": "5b172f2b-ede3-4fb1-da09-85de7c6672f5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è  No GPU available, but code would work if there was!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 4: Mixed Precision Training (2x Speed!)"
      ],
      "metadata": {
        "id": "fSVXu4sT_eLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 4: Mixed Precision Training\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTw3_Nwh_ZJ3",
        "outputId": "e4b46947-866f-419f-ccf8-024b2978bb4a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 4: Mixed Precision Training\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_mixed = Trainer(\n",
        "    accelerator='auto',\n",
        "    devices=1,\n",
        "    precision=16,           # Mixed precision - 2x faster!\n",
        "    max_epochs=1,\n",
        "    log_every_n_steps=20,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN_pQw7G_lrx",
        "outputId": "88a81ce5-04ef-43d2-e9a8-cb8f382d1e23"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:479: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Change: Add precision=16 for automatic mixed precision\")\n",
        "print(\"   Benefits: 2x faster training, half the memory usage\")\n",
        "print(\"   No code changes to your model!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm7SYlAb_qOi",
        "outputId": "3d72da0e-e4be-4561-946c-7b77f9056f91"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Change: Add precision=16 for automatic mixed precision\n",
            "   Benefits: 2x faster training, half the memory usage\n",
            "   No code changes to your model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 5: Multi-GPU Training\n"
      ],
      "metadata": {
        "id": "jKurTqPJ_xhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 5: Multi-GPU Training\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KVHoYfM_1-T",
        "outputId": "17c29f7b-dae8-4f66-b152-6c0fc501b61e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 5: Multi-GPU Training\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available() and torch.cuda.device_count() >= 2:\n",
        "    trainer_multi = Trainer(\n",
        "        accelerator='gpu',\n",
        "        devices=2,              # Use 2 GPUs\n",
        "        strategy='ddp',         # Distributed Data Parallel\n",
        "        max_epochs=1,\n",
        "    )\n",
        "    print(\"‚úÖ Code ready for 2-GPU training!\")\n",
        "    print(\"   Change: devices=1 ‚Üí devices=2\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Only {torch.cuda.device_count() if torch.cuda.is_available() else 0} GPU(s) available\")\n",
        "    print(\"   Code would work with 2+ GPUs!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnODBhpX_7qg",
        "outputId": "be6e0bc6-3faa-4439-dce2-dc656decf0e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è  Only 0 GPU(s) available\n",
            "   Code would work with 2+ GPUs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 6: With Callbacks (Production Ready)"
      ],
      "metadata": {
        "id": "X4hgijyg_-XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 6: Production Training with Callbacks\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGbNjtaHADOI",
        "outputId": "ec09af55-0561-402f-9eb3-33c21f7eb041"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 6: Production Training with Callbacks\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create useful callbacks\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    filename='cifar10-{epoch:02d}-{val_loss:.2f}',\n",
        "    save_top_k=2,\n",
        "    mode='min',\n",
        "    save_last=True,\n",
        ")\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    mode='min',\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "trainer_prod = Trainer(\n",
        "    accelerator='auto',\n",
        "    max_epochs=10,\n",
        "    callbacks=[checkpoint_callback, early_stop_callback],\n",
        "    log_every_n_steps=50,\n",
        "    gradient_clip_val=1.0,      # Prevent exploding gradients\n",
        "    accumulate_grad_batches=2,  # Simulate larger batch size\n",
        "    deterministic=True,         # Reproducible results\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0GEqU_QAG0h",
        "outputId": "45663e91-4cf7-4f0c-bee6-f69ae5b77e09"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Added production features with callbacks:\")\n",
        "print(\"   ‚Ä¢ Automatic checkpointing (saves best models)\")\n",
        "print(\"   ‚Ä¢ Early stopping (prevents overfitting)\")\n",
        "print(\"   ‚Ä¢ Gradient clipping (stabilizes training)\")\n",
        "print(\"   ‚Ä¢ Gradient accumulation (larger effective batch size)\")\n",
        "print(\"   ‚Ä¢ Deterministic training (reproducible)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dCp0inLAKdP",
        "outputId": "b0ff619b-cb61-405f-c47c-64780ffa30fc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added production features with callbacks:\n",
            "   ‚Ä¢ Automatic checkpointing (saves best models)\n",
            "   ‚Ä¢ Early stopping (prevents overfitting)\n",
            "   ‚Ä¢ Gradient clipping (stabilizes training)\n",
            "   ‚Ä¢ Gradient accumulation (larger effective batch size)\n",
            "   ‚Ä¢ Deterministic training (reproducible)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiements with different Learning Rates"
      ],
      "metadata": {
        "id": "PHoSupsBAju9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create models with different learning rates\n",
        "print(\"\\nCreating models with different learning rates...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKCUNJgBApYX",
        "outputId": "7b658922-51be-46c6-ccb8-1a9e6549cf3f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating models with different learning rates...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr_low = LitCIFAR(learning_rate=1e-4)   # Very low LR\n",
        "model_lr_med = LitCIFAR(learning_rate=1e-3)   # Medium LR (default)\n",
        "model_lr_high = LitCIFAR(learning_rate=1e-2)  # High LR"
      ],
      "metadata": {
        "id": "vYNZbBXdAvGS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer for experiments - FORCE CPU\n",
        "trainer_experiment = Trainer(\n",
        "    accelerator='cpu',          # Force CPU for consistent results\n",
        "    fast_dev_run=True,          # Only 1 batch per experiment\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=False, # Cleaner output\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip37YiNCAvyK",
        "outputId": "e93dc203-5c74-4b93-f8d1-1685a69e77de"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Testing different learning rates on CPU:\")\n",
        "print(\"   1. LR = 0.0001 (very low)\")\n",
        "print(\"   2. LR = 0.001  (medium - default)\")\n",
        "print(\"   3. LR = 0.01   (high)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuTwjRT5BVHP",
        "outputId": "2da24a2f-3f19-46fc-ec2b-d2a772726df2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Testing different learning rates on CPU:\n",
            "   1. LR = 0.0001 (very low)\n",
            "   2. LR = 0.001  (medium - default)\n",
            "   3. LR = 0.01   (high)\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run experiment 1: Very low learning rate\n",
        "print(\"\\n Testing LR = 0.0001 (very low)...\")\n",
        "trainer_experiment.fit(model_lr_low, data_module)\n",
        "\n",
        "# Reset data module for next experiment\n",
        "data_module.setup()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "e88161df772e427595861a5e1b8ec55e",
            "66effa98dc864a29a1574b9780a073f4"
          ]
        },
        "id": "IukAemeBBahf",
        "outputId": "657048bc-429d-4c7c-8df9-e6512f35e9bd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Testing LR = 0.0001 (very low)...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e88161df772e427595861a5e1b8ec55e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run experiment 2: Medium learning rate\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"\\n Testing LR = 0.001 (medium - default)...\")\n",
        "trainer_experiment.fit(model_lr_med, data_module)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPwr6lBlBg5x",
        "outputId": "5f4d90fb-426a-489d-d3c1-b0d88f974eb7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            " Testing LR = 0.001 (medium - default)...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset data module for next experiment\n",
        "data_module.setup()\n",
        "# Run experiment 3: High learning rate\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"\\n Testing LR = 0.01 (high)...\")\n",
        "trainer_experiment.fit(model_lr_high, data_module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAkwbSAdBnnO",
        "outputId": "d46d34c7-bbc4-4031-b5ad-dd12daad177a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            "==================================================\n",
            "\n",
            " Testing LR = 0.01 (high)...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\" Learning rate experiments complete!\")\n",
        "print(\"\\n Observations:\")\n",
        "print(\"   ‚Ä¢ Very low LR (0.0001): May converge slowly\")\n",
        "print(\"   ‚Ä¢ Medium LR (0.001): Good balance for most models\")\n",
        "print(\"   ‚Ä¢ High LR (0.01): May cause instability\")\n",
        "print(\"\\n Tip: Use fast_dev_run to quickly test hyperparameters!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6HvRaRCBt9G",
        "outputId": "4a81948c-b177-4598-b7d6-cfeddfab5861"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            " Learning rate experiments complete!\n",
            "\n",
            " Observations:\n",
            "   ‚Ä¢ Very low LR (0.0001): May converge slowly\n",
            "   ‚Ä¢ Medium LR (0.001): Good balance for most models\n",
            "   ‚Ä¢ High LR (0.01): May cause instability\n",
            "\n",
            " Tip: Use fast_dev_run to quickly test hyperparameters!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate Analysis\n"
      ],
      "metadata": {
        "id": "f4ZLeHHuB4qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Learning Rate Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Let's run a slightly longer experiment to see the difference\n",
        "print(\"\\nRunning longer experiment (3 batches) to see trends...\")\n",
        "\n",
        "# Reset models\n",
        "models = {\n",
        "    \"Low LR (1e-4)\": LitCIFAR(learning_rate=1e-4),\n",
        "    \"Medium LR (1e-3)\": LitCIFAR(learning_rate=1e-3),\n",
        "    \"High LR (1e-2)\": LitCIFAR(learning_rate=1e-2)\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDyrb7-1A8Lk",
        "outputId": "fe3f49d7-76d8-4594-98dc-e13297da7c23"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Learning Rate Analysis\n",
            "==================================================\n",
            "\n",
            "Running longer experiment (3 batches) to see trends...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset models\n",
        "models = {\n",
        "    \"Low LR (1e-4)\": LitCIFAR(learning_rate=1e-4),\n",
        "    \"Medium LR (1e-3)\": LitCIFAR(learning_rate=1e-3),\n",
        "    \"High LR (1e-2)\": LitCIFAR(learning_rate=1e-2)\n",
        "}\n",
        "\n",
        "trainer_analysis = Trainer(\n",
        "    accelerator='cpu',\n",
        "    max_epochs=1,\n",
        "    limit_train_batches=3,  # 3 batches to see trend\n",
        "    limit_val_batches=2,    # 2 validation batches\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=False,\n",
        ")\n",
        "\n",
        "print(\"\\nTraining each model for 3 batches...\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AlrCWvWB-z3",
        "outputId": "6953e4a2-d989-4e2c-d8b4-4f65a115f98b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training each model for 3 batches...\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n Training: {name}\")\n",
        "    trainer_analysis.fit(model, data_module)\n",
        "\n",
        "    # Store the final loss for comparison\n",
        "    final_loss = trainer_analysis.callback_metrics.get('train_loss', torch.tensor(0.0))\n",
        "    if isinstance(final_loss, torch.Tensor):\n",
        "        final_loss = final_loss.item()\n",
        "    results[name] = final_loss\n",
        "\n",
        "    # Reset data module for next model\n",
        "    data_module.setup()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\" RESULTS SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "for name, loss in results.items():\n",
        "    print(f\"{name:20s} ‚Üí Final Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\n Key Insights:\")\n",
        "print(\"1. Higher learning rates converge faster initially\")\n",
        "print(\"2. Very low learning rates need more time to converge\")\n",
        "print(\"3. Medium LR (1e-3) is usually a good starting point\")\n",
        "print(\"4. Use fast_dev_run to quickly test different LRs!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762,
          "referenced_widgets": [
            "a68b8c5ca662463d971f1f1221b73dfb",
            "1b76a47f3bab4bea90d7e80555f9a612",
            "92cc99e211b94228bef5a3043c1777a3",
            "df7476d7792a416e87049843fec16303",
            "abe8d78f09d54841a5a06a0166e8b615",
            "74a1ec37add047a8b79e875c3788d371"
          ]
        },
        "id": "LjDu4f3UCCUQ",
        "outputId": "27437c54-ff11-4e86-dec9-dbd6acfe40ab"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training: Low LR (1e-4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a68b8c5ca662463d971f1f1221b73dfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (3)\n",
              "is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you \n",
              "want to see logs for the training epoch.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (3)\n",
              "is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you \n",
              "want to see logs for the training epoch.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            " Training: Medium LR (1e-3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92cc99e211b94228bef5a3043c1777a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /content/lightning_logs/version_1/checkpoints exists and is not empty.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            " Training: High LR (1e-2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abe8d78f09d54841a5a06a0166e8b615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            "==================================================\n",
            " RESULTS SUMMARY:\n",
            "--------------------------------------------------\n",
            "Low LR (1e-4)        ‚Üí Final Loss: 2.2848\n",
            "Medium LR (1e-3)     ‚Üí Final Loss: 0.0000\n",
            "High LR (1e-2)       ‚Üí Final Loss: 0.0000\n",
            "\n",
            " Key Insights:\n",
            "1. Higher learning rates converge faster initially\n",
            "2. Very low learning rates need more time to converge\n",
            "3. Medium LR (1e-3) is usually a good starting point\n",
            "4. Use fast_dev_run to quickly test different LRs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Visualization (CPU)"
      ],
      "metadata": {
        "id": "VIBRfjf3C9pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create fresh model for visualization\n",
        "model_viz = LitCIFAR(learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "opc0PmWQCFaT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for visualization - ON CPU\n",
        "trainer_viz = Trainer(\n",
        "    accelerator='cpu',           # Explicitly use CPU\n",
        "    max_epochs=2,               # 2 epochs for better visualization\n",
        "    limit_train_batches=50,      # 50 batches for meaningful trend\n",
        "    limit_val_batches=20,        # 20 validation batches\n",
        "    log_every_n_steps=10,        # Log every 10 steps\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=True,   # Show model summary\n",
        "    callbacks=[],               # No callbacks for cleaner output\n",
        ")\n",
        "\n",
        "print(\"\\n Starting CPU training for visualization...\")\n",
        "print(\"   Training for 2 epochs (50 batches per epoch)\")\n",
        "print(\"   Watch the progress bar and metrics update!\")\n",
        "print(\"\\n\" + \"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFtJxGW0CT6U",
        "outputId": "b171ad59-f658-43d7-e75b-357513a01b87"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Starting CPU training for visualization...\n",
            "   Training for 2 epochs (50 batches per epoch)\n",
            "   Watch the progress bar and metrics update!\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = trainer_viz.fit(model_viz, data_module)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"CPU Training Complete!\")\n",
        "print(\"\\n What just happened automatically:\")\n",
        "print(\"   ‚úì Training loop executed\")\n",
        "print(\"   ‚úì Validation after each epoch\")\n",
        "print(\"   ‚úì Loss and accuracy logged\")\n",
        "print(\"   ‚úì Progress tracked with ETA\")\n",
        "print(\"   ‚úì All on CPU with zero GPU code!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549,
          "referenced_widgets": [
            "ad06c259e55e4cf8a5b170541c98d401",
            "34cead0f85d844e7abd8933076654ada"
          ]
        },
        "id": "bPziKc_TCV0l",
        "outputId": "a08c6da8-4832-485c-c023-5cc68822bfca"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 545 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 545 K                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 10                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 545 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 545 K                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 10                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad06c259e55e4cf8a5b170541c98d401"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "CPU Training Complete!\n",
            "\n",
            " What just happened automatically:\n",
            "   ‚úì Training loop executed\n",
            "   ‚úì Validation after each epoch\n",
            "   ‚úì Loss and accuracy logged\n",
            "   ‚úì Progress tracked with ETA\n",
            "   ‚úì All on CPU with zero GPU code!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Check the metrics above:\")\n",
        "print(\"   ‚Ä¢ train_loss: Decreased over time (good!)\")\n",
        "print(\"   ‚Ä¢ train_acc: Increased (learning happening!)\")\n",
        "print(\"   ‚Ä¢ val_loss/val_acc: Model generalizing\")\n",
        "\n",
        "print(\"\\n Try changing these and re-running:\")\n",
        "print(\"   ‚Ä¢ max_epochs=2 ‚Üí max_epochs=5\")\n",
        "print(\"   ‚Ä¢ learning_rate=1e-3 ‚Üí learning_rate=1e-2\")\n",
        "print(\"   ‚Ä¢ Add EarlyStopping callback\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk5LsTAUCa-N",
        "outputId": "583bc53d-2328-4c66-ece9-2853dca22c4e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Check the metrics above:\n",
            "   ‚Ä¢ train_loss: Decreased over time (good!)\n",
            "   ‚Ä¢ train_acc: Increased (learning happening!)\n",
            "   ‚Ä¢ val_loss/val_acc: Model generalizing\n",
            "\n",
            " Try changing these and re-running:\n",
            "   ‚Ä¢ max_epochs=2 ‚Üí max_epochs=5\n",
            "   ‚Ä¢ learning_rate=1e-3 ‚Üí learning_rate=1e-2\n",
            "   ‚Ä¢ Add EarlyStopping callback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5CQ-fFHCfYO"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}