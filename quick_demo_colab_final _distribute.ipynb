{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "491944ab9492422b88ee186f15b749d7": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_47497b1d753e43f889cc6b88cbd76b8a",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 1/1 \u001b[2m0:00:00 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mtrain_loss: 2.305 train_acc: 0.109\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">train_loss: 2.305 train_acc: 0.109</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "47497b1d753e43f889cc6b88cbd76b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc0a7d3d36f4f70afa9669fff9048f4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_5079c45c17c44819a57f115af4e018e7",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 704/704 \u001b[2m0:01:20 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m8.91it/s\u001b[0m \u001b[3mv_num: 0.000 train_loss: 1.049    \u001b[0m\n                                                                                 \u001b[3mtrain_acc: 0.625                  \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 704/704 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:01:20 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">8.91it/s</span> <span style=\"font-style: italic\">v_num: 0.000 train_loss: 1.049    </span>\n                                                                                 <span style=\"font-style: italic\">train_acc: 0.625                  </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "5079c45c17c44819a57f115af4e018e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0be2e0441d504988bc4abe2a7068b776": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_591ddf2fa4474535a361aa7d0ff67243",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 1/1 \u001b[2m0:00:00 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mtrain_loss: 2.308 train_acc: 0.078\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">train_loss: 2.308 train_acc: 0.078</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "591ddf2fa4474535a361aa7d0ff67243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaeed640b261491b934d1e8f00d08ac5": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_304fee3877ea4ce797a70e2e3930009a",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 0/0  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 3/3 \u001b[2m0:00:00 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m8.91it/s\u001b[0m \u001b[3mv_num: 1.000 train_loss: 2.313      \u001b[0m\n                                                                               \u001b[3mtrain_acc: 0.109                    \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/0  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 3/3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">8.91it/s</span> <span style=\"font-style: italic\">v_num: 1.000 train_loss: 2.313      </span>\n                                                                               <span style=\"font-style: italic\">train_acc: 0.109                    </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "304fee3877ea4ce797a70e2e3930009a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de0c013d8244762b68e60c972f3258f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_97fb1dd0d48c40099c1097e0ff5f0bfd",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "97fb1dd0d48c40099c1097e0ff5f0bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "646d3dcbdafb419d85fe1214485055d1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_be919ab7eb9946499ad7ac413b073d3f",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "be919ab7eb9946499ad7ac413b073d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efda5c6941e24a968ffabdb82ee4bf6a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_73e69cb229e845878dba48075c60e6c9",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 1/1  \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 50/50 \u001b[2m0:00:06 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m7.89it/s\u001b[0m \u001b[3mv_num: 2.000 train_loss: 1.636      \u001b[0m\n                                                                               \u001b[3mtrain_acc: 0.406 val_loss: 1.817    \u001b[0m\n                                                                               \u001b[3mval_acc: 0.347                      \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 1/1  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 50/50 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:06 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">7.89it/s</span> <span style=\"font-style: italic\">v_num: 2.000 train_loss: 1.636      </span>\n                                                                               <span style=\"font-style: italic\">train_acc: 0.406 val_loss: 1.817    </span>\n                                                                               <span style=\"font-style: italic\">val_acc: 0.347                      </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "73e69cb229e845878dba48075c60e6c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö° PyTorch Lightning - Interactive Demo\n",
        "\n",
        "**Instructions:**\n",
        "*   Run each cell to see Lightning in action - no prior setup needed!\n",
        "\n",
        "**What you'll learn:**\n",
        "1. How Lightning organizes PyTorch code\n",
        "2. One-line hardware scaling (CPU ‚Üí GPU ‚Üí Multi-GPU)\n",
        "3. Automatic best practices (logging, checkpointing, early stopping)\n",
        "4. Debugging superpowers\n"
      ],
      "metadata": {
        "id": "B40RyJxJ7KBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Part 1: Setup & Installation"
      ],
      "metadata": {
        "id": "QhQLejJ_7qfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install (if needed)\n",
        "!pip install torch torchvision lightning matplotlib\n",
        "\n",
        "# Cell 2: Show data\n",
        "print(\"This is CIFAR-10 data we'll train on...\")\n",
        "# Shows images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlKG53eX6xYx",
        "outputId": "58e16886-cc08-4211-f50e-74c731b89e5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.6.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.11)\n",
            "Downloading lightning-2.6.0-py3-none-any.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m846.0/846.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.6.0 lightning-utilities-0.15.2 pytorch-lightning-2.6.0 torchmetrics-1.8.2\n",
            "This is CIFAR-10 data we'll train on...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Imports"
      ],
      "metadata": {
        "id": "RfNGUl4C7vxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Core\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# TorchVision for datasets\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# System\n",
        "import time\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Lightning version: {pl.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pyMjHCl7t_f",
        "outputId": "3d4de197-791f-4c68-ec75-d2836a22a341"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All imports successful!\n",
            "PyTorch version: 2.9.0+cpu\n",
            "Lightning version: 2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Part 2: Explore CIFAR-10 Dataset\n",
        "\n",
        "We'll use the CIFAR-10 dataset: 60,000; 32x32 color images in 10 classes"
      ],
      "metadata": {
        "id": "dL8VwHWs76jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "JmPffrxQ750q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "print(\"üì• Loading CIFAR-10 dataset...\")\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v9aFJVi8HsI",
        "outputId": "0df74cde-5bab-4355-e8ef-b6443493244c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading CIFAR-10 dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:02<00:00, 80.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset statistics\n",
        "print(f\"‚úÖ Training samples: {len(trainset):,}\")\n",
        "print(f\"‚úÖ Test samples: {len(testset):,}\")\n",
        "\n",
        "# Class names\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "print(f\"‚úÖ Classes: {classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6vbIUge8J-u",
        "outputId": "e56589c5-e889-4341-84a3-469ab79db6d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training samples: 50,000\n",
            "‚úÖ Test samples: 10,000\n",
            "‚úÖ Classes: ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some samples from the dataset\n",
        "\n",
        "def show_images(images, labels, n=4):\n",
        "    \"\"\"Display n images with their labels\"\"\"\n",
        "    fig, axes = plt.subplots(1, n, figsize=(15, 4))\n",
        "    for i in range(n):\n",
        "        # Unnormalize the image\n",
        "        img = images[i] / 2 + 0.5  # Scale from [-1, 1] to [0, 1]\n",
        "        axes[i].imshow(img.permute(1, 2, 0))  # CHW ‚Üí HWC\n",
        "        axes[i].set_title(f\"Label: {classes[labels[i]]}\")\n",
        "        axes[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oVlBSo2Z8MfX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of images\n",
        "trainloader = DataLoader(trainset, batch_size=8, shuffle=True)\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "print(\"üñºÔ∏è Sample images from CIFAR-10:\")\n",
        "show_images(images, labels, n=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "B40oi_ya8PXc",
        "outputId": "e5c4e0a9-96b8-49bd-b032-bd9ba16e2d1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñºÔ∏è Sample images from CIFAR-10:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèóÔ∏è Part 3: Create a LightningModule\n",
        "\n",
        "**Key Concept:** LightningModule organizes your PyTorch code into 6 logical sections:\n",
        "  1. Initialization (`__init__`)\n",
        "  2. Training loop (`training_step`)\n",
        "  3. Validation loop (`validation_step`)\n",
        "  4. Test loop (`test_step`)\n",
        "  5. Prediction loop (`predict_step`)\n",
        "  6. Optimizers (`configure_optimizers`)"
      ],
      "metadata": {
        "id": "T8n3AacO8Wb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, create a pure PyTorch model (no Lightning here!)\n",
        "# This is the model architecture you would write anyway\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"A simple CNN for CIFAR-10 classification - Pure PyTorch!\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # 3 input channels (RGB), 32 output\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Reduces spatial dimensions by half\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # After 2 pooling layers: 32x32 ‚Üí 16x16 ‚Üí 8x8\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10 classes\n",
        "\n",
        "        # Regularization\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass - define how data flows through the network\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Conv ‚Üí ReLU ‚Üí Pool\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Another conv block\n",
        "\n",
        "        x = torch.flatten(x, 1)  # Flatten for fully connected layers\n",
        "        x = F.relu(self.fc1(x))  # Fully connected with ReLU\n",
        "        x = self.dropout(x)      # Regularization\n",
        "        x = self.fc2(x)          # Output layer (no activation - softmax in loss)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "se_z9Mm-8R-7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our pure PyTorch model\n",
        "print(\"Testing pure PyTorch model...\")\n",
        "sample_input = torch.randn(4, 3, 32, 32)  # Batch of 4, 3 channels, 32x32 images\n",
        "model = SimpleCNN()\n",
        "output = model(sample_input)\n",
        "print(f\"Input shape: {sample_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meW0EF3I8q1H",
        "outputId": "77bd2550-25c6-4ba4-f95d-510aa5e4f11f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing pure PyTorch model...\n",
            "Input shape: torch.Size([4, 3, 32, 32])\n",
            "Output shape: torch.Size([4, 10])\n",
            "Model has 545,098 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now wrap it in a LightningModule\n",
        "**Magic happens here:** LightningModule takes your PyTorch model and adds training logic"
      ],
      "metadata": {
        "id": "bAF7U8DM8zKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitCIFAR(pl.LightningModule):\n",
        "    \"\"\"LightningModule that wraps our PyTorch model with training logic\"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=1e-3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Save hyperparameters (auto-logged!)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Use our pure PyTorch model - no changes needed!\n",
        "        self.model = SimpleCNN()\n",
        "\n",
        "        # Loss function\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Track metrics\n",
        "        from torchmetrics import Accuracy # Import Accuracy from torchmetrics\n",
        "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    # ========== 1. Forward Pass ==========\n",
        "    def forward(self, x):\n",
        "        \"\"\"Inference - same as PyTorch forward\"\"\"\n",
        "        return self.model(x)\n",
        "\n",
        "    # ========== 2. Training Step ==========\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"What happens in ONE training batch\"\"\"\n",
        "        x, y = batch\n",
        "\n",
        "        # Forward pass\n",
        "        y_hat = self(x)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "\n",
        "        # Compute accuracy\n",
        "        preds = torch.argmax(y_hat, dim=1)\n",
        "        self.train_acc(preds, y)\n",
        "\n",
        "        # Log everything - automatically sent to TensorBoard, etc.\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.log('train_acc', self.train_acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # ========== 3. Validation Step ==========\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"What happens in ONE validation batch\"\"\"\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.loss_fn(y_hat, y)\n",
        "\n",
        "        # Compute accuracy\n",
        "        preds = torch.argmax(y_hat, dim=1)\n",
        "        self.val_acc(preds, y)\n",
        "\n",
        "        # Log validation metrics\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # ========== 4. Test Step ==========\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        \"\"\"What happens in ONE test batch\"\"\"\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "\n",
        "        # Compute test accuracy\n",
        "        preds = torch.argmax(y_hat, dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "        self.log('test_acc', acc)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    # ========== 5. Configure Optimizers ==========\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Define optimizers and learning rate schedulers\"\"\"\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
        "\n",
        "        # Add a learning rate scheduler\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': scheduler,\n",
        "            'monitor': 'val_loss'  # Which metric to monitor for scheduling\n",
        "        }\n",
        "\n",
        "print(\"LightningModule created!\")\n",
        "print(\"Notice: We separated the WHAT (model, loss) from the HOW (training loop)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2S15vG48tB_",
        "outputId": "05f6dbaa-1d89-447e-aa7d-635827193a3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightningModule created!\n",
            "Notice: We separated the WHAT (model, loss) from the HOW (training loop)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Part 4: Create a LightningDataModule\n",
        "\n",
        "**Key Concept:** DataModule organizes your data loading code for reproducibility"
      ],
      "metadata": {
        "id": "llSiA2Gw9FS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10DataModule(pl.LightningDataModule):\n",
        "    \"\"\"Handles all data loading and preprocessing for CIFAR-10\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size=64):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Download data - runs only once on 1 GPU\"\"\"\n",
        "        torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "        torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"Split data - runs on every GPU\"\"\"\n",
        "        if stage == 'fit' or stage is None:\n",
        "            # Load full training set\n",
        "            full_train = torchvision.datasets.CIFAR10(\n",
        "                root='./data', train=True, transform=self.transform\n",
        "            )\n",
        "            # Split into train/validation (45k/5k)\n",
        "            self.train_data, self.val_data = random_split(full_train, [45000, 5000])\n",
        "            print(f\"Train: {len(self.train_data):,} samples\")\n",
        "            print(f\"Validation: {len(self.val_data):,} samples\")\n",
        "\n",
        "        if stage == 'test' or stage is None:\n",
        "            # Test set\n",
        "            self.test_data = torchvision.datasets.CIFAR10(\n",
        "                root='./data', train=False, transform=self.transform\n",
        "            )\n",
        "            print(f\"Test: {len(self.test_data):,} samples\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_data, batch_size=self.batch_size,\n",
        "                         shuffle=True, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_data, batch_size=self.batch_size,\n",
        "                         shuffle=False, num_workers=2)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_data, batch_size=self.batch_size,\n",
        "                         shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "OfWXCzE18-lJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and setup our data module\n",
        "print(\"Creating DataModule...\")\n",
        "data_module = CIFAR10DataModule(batch_size=64)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "\n",
        "# Show data loader statistics\n",
        "print(f\"\\n DataLoader statistics:\")\n",
        "print(f\"Train batches: {len(data_module.train_dataloader()):,}\")\n",
        "print(f\"Val batches: {len(data_module.val_dataloader()):,}\")\n",
        "print(f\"Test batches: {len(data_module.test_dataloader()):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgkO4rBe9OWp",
        "outputId": "fd2765e9-ce2b-470c-b705-60757845c840"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating DataModule...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            " DataLoader statistics:\n",
            "Train batches: 704\n",
            "Val batches: 79\n",
            "Test batches: 157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Part 5: The Trainer - Lightning's Superpower\n",
        "\n",
        "**This is where the magic happens!**  \n",
        "\n",
        "### The `Trainer` class automates everything you used to write manually:\n",
        "Training loop\n",
        "- Validation loop\n",
        "- Checkpointing\n",
        "- Logging\n",
        "- Multi-GPU training\n",
        "- Early stopping\n",
        "- And much more!"
      ],
      "metadata": {
        "id": "Qr0cCIDS9jUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our model\n",
        "model = LitCIFAR(learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "8O_78PlM9Srx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 1: Fast Development Run\n",
        "\n",
        "**Problem:** In PyTorch, you write the whole training loop before you can test if it works.  \n",
        "**Solution:** `fast_dev_run=True` runs 1 batch to verify everything works!"
      ],
      "metadata": {
        "id": "axgad_a_-Ias"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DEMO 1: Fast Development Run\")\n",
        "print(\"=\" * 50)\n",
        "trainer_dev = Trainer(\n",
        "    fast_dev_run=True,      # Runs only 1 batch\n",
        "    max_epochs=1,           # Just 1 epoch\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=True,\n",
        ")\n",
        "\n",
        "print(\"\\nRunning fast_dev_run (should take < 10 seconds)...\")\n",
        "trainer_dev.fit(model, data_module)\n",
        "\n",
        "print(\"\\n Success! Our pipeline works.\")\n",
        "print(\"   No need to write training loops just to test if code works!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536,
          "referenced_widgets": [
            "491944ab9492422b88ee186f15b749d7",
            "47497b1d753e43f889cc6b88cbd76b8a"
          ]
        },
        "id": "w816GQFA9wtT",
        "outputId": "a87ee1d2-72cc-410a-9213-4c580e59b96f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEMO 1: Fast Development Run\n",
            "==================================================\n",
            "\n",
            "Running fast_dev_run (should take < 10 seconds)...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 545 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 545 K                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 10                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 545 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 545 K                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 10                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "491944ab9492422b88ee186f15b749d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Success! Our pipeline works.\n",
            "   No need to write training loops just to test if code works!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 2: CPU Training (Baseline)\n"
      ],
      "metadata": {
        "id": "Rb33MgFH-YcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 2: CPU Training\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBtrzdOk_DLC",
        "outputId": "a513872e-0063-4706-adee-95d83d0a8a78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 2: CPU Training\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_cpu = Trainer(\n",
        "    accelerator='cpu',      # Force CPU\n",
        "    max_epochs=1,           # Just 1 epoch for demo\n",
        "    log_every_n_steps=20,   # Log every 20 batches\n",
        "    enable_progress_bar=True,\n",
        ")\n",
        "\n",
        "print(\"\\nTraining on CPU...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLInzrI_-S8N",
        "outputId": "9ba38efe-f76e-4ad0-8089-9c56194605b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on CPU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run:\n",
        "trainer_cpu.fit(model, data_module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "4bc0a7d3d36f4f70afa9669fff9048f4",
            "5079c45c17c44819a57f115af4e018e7"
          ]
        },
        "id": "aHYlCWly-jZf",
        "outputId": "e92a5e7a-386c-41e6-c46b-113ec97c692a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 545 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 545 K                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 10                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 545 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 545 K                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 10                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bc0a7d3d36f4f70afa9669fff9048f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Same code runs on CPU with zero changes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y95va1gq-nI0",
        "outputId": "71b6122f-df40-4ee6-f67b-bdd9318ded29"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Same code runs on CPU with zero changes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 3: GPU Training (Automatic Detection)"
      ],
      "metadata": {
        "id": "Y8U46mdD-7di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 3: GPU Training (Auto-detect)\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiXTPGe9-rIz",
        "outputId": "251063d6-eab0-49b2-9351-b85806913ccd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 3: GPU Training (Auto-detect)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what hardware is available\n",
        "print(f\"Hardware check:\")\n",
        "print(f\"   CPU cores: Available\")\n",
        "print(f\"   GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU count: {torch.cuda.device_count()}\")\n",
        "    print(f\"   GPU name: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKSxMxYx--x6",
        "outputId": "e5bfb9d3-a33d-4285-d5a1-febbd9d51176"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hardware check:\n",
            "   CPU cores: Available\n",
            "   GPU available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_gpu = Trainer(\n",
        "    accelerator='auto',     # Automatically picks GPU if available\n",
        "    devices='auto',         # Use all available devices\n",
        "    max_epochs=1,\n",
        "    log_every_n_steps=20,\n",
        "    enable_progress_bar=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjlT44rz_Kg9",
        "outputId": "d74109df-c0ae-4410-9416-1822ed5c1dde"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Key insight: Change 'cpu' to 'auto' to use GPU\")\n",
        "print(\"   No code changes in model or data!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSqK8vwo_NxV",
        "outputId": "619e9e1b-ed35-4599-f39d-9a0e1870cf44"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Key insight: Change 'cpu' to 'auto' to use GPU\n",
            "   No code changes in model or data!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run if GPU is available:\n",
        "if torch.cuda.is_available():\n",
        "  trainer_gpu.fit(model, data_module)\n",
        "else:\n",
        "  print(\"‚ö†Ô∏è  No GPU available, but code would work if there was!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HitJmXet_Q5X",
        "outputId": "f7a208d4-6a67-4e89-992b-deeb3e495234"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è  No GPU available, but code would work if there was!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 4: Mixed Precision Training (2x Speed!)"
      ],
      "metadata": {
        "id": "fSVXu4sT_eLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 4: Mixed Precision Training\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTw3_Nwh_ZJ3",
        "outputId": "9d8690e8-01d6-4d5f-e520-90b3a29ffb7c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 4: Mixed Precision Training\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_mixed = Trainer(\n",
        "    accelerator='auto',\n",
        "    devices=1,\n",
        "    precision=16,           # Mixed precision - 2x faster!\n",
        "    max_epochs=1,\n",
        "    log_every_n_steps=20,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN_pQw7G_lrx",
        "outputId": "537ce455-3e1d-409b-8fe0-4bd6292b9dc2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:479: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Change: Add precision=16 for automatic mixed precision\")\n",
        "print(\"   Benefits: 2x faster training, half the memory usage\")\n",
        "print(\"   No code changes to your model!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm7SYlAb_qOi",
        "outputId": "caf22058-3c8c-4f74-910e-ee1fbec5eb9b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Change: Add precision=16 for automatic mixed precision\n",
            "   Benefits: 2x faster training, half the memory usage\n",
            "   No code changes to your model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 5: Multi-GPU Training\n"
      ],
      "metadata": {
        "id": "jKurTqPJ_xhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 5: Multi-GPU Training\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KVHoYfM_1-T",
        "outputId": "aa76d0c3-7386-40bd-aea7-c46918fec52f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 5: Multi-GPU Training\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available() and torch.cuda.device_count() >= 2:\n",
        "    trainer_multi = Trainer(\n",
        "        accelerator='gpu',\n",
        "        devices=2,              # Use 2 GPUs\n",
        "        strategy='ddp',         # Distributed Data Parallel\n",
        "        max_epochs=1,\n",
        "    )\n",
        "    print(\"‚úÖ Code ready for 2-GPU training!\")\n",
        "    print(\"   Change: devices=1 ‚Üí devices=2\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Only {torch.cuda.device_count() if torch.cuda.is_available() else 0} GPU(s) available\")\n",
        "    print(\"   Code would work with 2+ GPUs!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnODBhpX_7qg",
        "outputId": "48db71b4-c7a1-4713-eca4-2037c12776ee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è  Only 0 GPU(s) available\n",
            "   Code would work with 2+ GPUs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 6: With Callbacks (Production Ready)"
      ],
      "metadata": {
        "id": "X4hgijyg_-XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n DEMO 6: Production Training with Callbacks\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGbNjtaHADOI",
        "outputId": "46bbe2ef-033d-4f0f-9cee-1023e9af100b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " DEMO 6: Production Training with Callbacks\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create useful callbacks\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    filename='cifar10-{epoch:02d}-{val_loss:.2f}',\n",
        "    save_top_k=2,\n",
        "    mode='min',\n",
        "    save_last=True,\n",
        ")\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    mode='min',\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "trainer_prod = Trainer(\n",
        "    accelerator='auto',\n",
        "    max_epochs=10,\n",
        "    callbacks=[checkpoint_callback, early_stop_callback],\n",
        "    log_every_n_steps=50,\n",
        "    gradient_clip_val=1.0,      # Prevent exploding gradients\n",
        "    accumulate_grad_batches=2,  # Simulate larger batch size\n",
        "    deterministic=True,         # Reproducible results\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0GEqU_QAG0h",
        "outputId": "8242be71-7523-473e-eebe-b14a9c65c7d7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Added production features with callbacks:\")\n",
        "print(\"   ‚Ä¢ Automatic checkpointing (saves best models)\")\n",
        "print(\"   ‚Ä¢ Early stopping (prevents overfitting)\")\n",
        "print(\"   ‚Ä¢ Gradient clipping (stabilizes training)\")\n",
        "print(\"   ‚Ä¢ Gradient accumulation (larger effective batch size)\")\n",
        "print(\"   ‚Ä¢ Deterministic training (reproducible)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dCp0inLAKdP",
        "outputId": "d7a003e3-66a4-43e5-9eee-0297938d64da"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added production features with callbacks:\n",
            "   ‚Ä¢ Automatic checkpointing (saves best models)\n",
            "   ‚Ä¢ Early stopping (prevents overfitting)\n",
            "   ‚Ä¢ Gradient clipping (stabilizes training)\n",
            "   ‚Ä¢ Gradient accumulation (larger effective batch size)\n",
            "   ‚Ä¢ Deterministic training (reproducible)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiements with different Learning Rates"
      ],
      "metadata": {
        "id": "PHoSupsBAju9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create models with different learning rates\n",
        "print(\"\\nCreating models with different learning rates...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKCUNJgBApYX",
        "outputId": "e95b0ebf-52d8-4fd4-b64b-689e5f57e406"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating models with different learning rates...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr_low = LitCIFAR(learning_rate=1e-4)   # Very low LR\n",
        "model_lr_med = LitCIFAR(learning_rate=1e-3)   # Medium LR (default)\n",
        "model_lr_high = LitCIFAR(learning_rate=1e-2)  # High LR"
      ],
      "metadata": {
        "id": "vYNZbBXdAvGS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer for experiments - FORCE CPU\n",
        "trainer_experiment = Trainer(\n",
        "    accelerator='cpu',          # Force CPU for consistent results\n",
        "    fast_dev_run=True,          # Only 1 batch per experiment\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=False, # Cleaner output\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip37YiNCAvyK",
        "outputId": "729337e8-3035-47ee-a359-5bdaab0e8ae5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Testing different learning rates on CPU:\")\n",
        "print(\"   1. LR = 0.0001 (very low)\")\n",
        "print(\"   2. LR = 0.001  (medium - default)\")\n",
        "print(\"   3. LR = 0.01   (high)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuTwjRT5BVHP",
        "outputId": "c1662c6f-54e4-4d34-ac85-38aa3c7b5c57"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Testing different learning rates on CPU:\n",
            "   1. LR = 0.0001 (very low)\n",
            "   2. LR = 0.001  (medium - default)\n",
            "   3. LR = 0.01   (high)\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run experiment 1: Very low learning rate\n",
        "print(\"\\n Testing LR = 0.0001 (very low)...\")\n",
        "trainer_experiment.fit(model_lr_low, data_module)\n",
        "\n",
        "# Reset data module for next experiment\n",
        "data_module.setup()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172,
          "referenced_widgets": [
            "0be2e0441d504988bc4abe2a7068b776",
            "591ddf2fa4474535a361aa7d0ff67243"
          ]
        },
        "id": "IukAemeBBahf",
        "outputId": "3a55e41d-e9fc-4ef2-e449-7166744ad55d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Testing LR = 0.0001 (very low)...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0be2e0441d504988bc4abe2a7068b776"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run experiment 2: Medium learning rate\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"\\n Testing LR = 0.001 (medium - default)...\")\n",
        "trainer_experiment.fit(model_lr_med, data_module)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPwr6lBlBg5x",
        "outputId": "5e4ffd2f-a13f-4cc9-e15a-9893fb1abae9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            " Testing LR = 0.001 (medium - default)...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset data module for next experiment\n",
        "data_module.setup()\n",
        "# Run experiment 3: High learning rate\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"\\n Testing LR = 0.01 (high)...\")\n",
        "trainer_experiment.fit(model_lr_high, data_module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAkwbSAdBnnO",
        "outputId": "797e26ad-e06e-4c9d-c400-1972d9fc5850"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            "==================================================\n",
            "\n",
            " Testing LR = 0.01 (high)...\n",
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\" Learning rate experiments complete!\")\n",
        "print(\"\\n Observations:\")\n",
        "print(\"   ‚Ä¢ Very low LR (0.0001): May converge slowly\")\n",
        "print(\"   ‚Ä¢ Medium LR (0.001): Good balance for most models\")\n",
        "print(\"   ‚Ä¢ High LR (0.01): May cause instability\")\n",
        "print(\"\\n Tip: Use fast_dev_run to quickly test hyperparameters!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6HvRaRCBt9G",
        "outputId": "eb08354a-a5d7-4e61-f136-25906d23d299"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            " Learning rate experiments complete!\n",
            "\n",
            " Observations:\n",
            "   ‚Ä¢ Very low LR (0.0001): May converge slowly\n",
            "   ‚Ä¢ Medium LR (0.001): Good balance for most models\n",
            "   ‚Ä¢ High LR (0.01): May cause instability\n",
            "\n",
            " Tip: Use fast_dev_run to quickly test hyperparameters!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate Analysis\n"
      ],
      "metadata": {
        "id": "f4ZLeHHuB4qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Learning Rate Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Let's run a slightly longer experiment to see the difference\n",
        "print(\"\\nRunning longer experiment (3 batches) to see trends...\")\n",
        "\n",
        "# Reset models\n",
        "models = {\n",
        "    \"Low LR (1e-4)\": LitCIFAR(learning_rate=1e-4),\n",
        "    \"Medium LR (1e-3)\": LitCIFAR(learning_rate=1e-3),\n",
        "    \"High LR (1e-2)\": LitCIFAR(learning_rate=1e-2)\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDyrb7-1A8Lk",
        "outputId": "8eec8c50-9cc7-44a5-bcda-ea2b12ef5682"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Learning Rate Analysis\n",
            "==================================================\n",
            "\n",
            "Running longer experiment (3 batches) to see trends...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset models\n",
        "models = {\n",
        "    \"Low LR (1e-4)\": LitCIFAR(learning_rate=1e-4),\n",
        "    \"Medium LR (1e-3)\": LitCIFAR(learning_rate=1e-3),\n",
        "    \"High LR (1e-2)\": LitCIFAR(learning_rate=1e-2)\n",
        "}\n",
        "\n",
        "trainer_analysis = Trainer(\n",
        "    accelerator='cpu',\n",
        "    max_epochs=1,\n",
        "    limit_train_batches=3,  # 3 batches to see trend\n",
        "    limit_val_batches=2,    # 2 validation batches\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=False,\n",
        ")\n",
        "\n",
        "print(\"\\nTraining each model for 3 batches...\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AlrCWvWB-z3",
        "outputId": "0858dca3-2e97-4f7a-ae26-85d9aa146c30"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training each model for 3 batches...\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n Training: {name}\")\n",
        "    trainer_analysis.fit(model, data_module)\n",
        "\n",
        "    # Store the final loss for comparison\n",
        "    final_loss = trainer_analysis.callback_metrics.get('train_loss', torch.tensor(0.0))\n",
        "    if isinstance(final_loss, torch.Tensor):\n",
        "        final_loss = final_loss.item()\n",
        "    results[name] = final_loss\n",
        "\n",
        "    # Reset data module for next model\n",
        "    data_module.setup()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\" RESULTS SUMMARY:\")\n",
        "print(\"-\" * 50)\n",
        "for name, loss in results.items():\n",
        "    print(f\"{name:20s} ‚Üí Final Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"\\n Key Insights:\")\n",
        "print(\"1. Higher learning rates converge faster initially\")\n",
        "print(\"2. Very low learning rates need more time to converge\")\n",
        "print(\"3. Medium LR (1e-3) is usually a good starting point\")\n",
        "print(\"4. Use fast_dev_run to quickly test different LRs!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776,
          "referenced_widgets": [
            "eaeed640b261491b934d1e8f00d08ac5",
            "304fee3877ea4ce797a70e2e3930009a",
            "7de0c013d8244762b68e60c972f3258f",
            "97fb1dd0d48c40099c1097e0ff5f0bfd",
            "646d3dcbdafb419d85fe1214485055d1",
            "be919ab7eb9946499ad7ac413b073d3f"
          ]
        },
        "id": "LjDu4f3UCCUQ",
        "outputId": "e3229fd7-19bd-4a73-be07-1ec245458cc5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training: Low LR (1e-4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eaeed640b261491b934d1e8f00d08ac5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (3)\n",
              "is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you \n",
              "want to see logs for the training epoch.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (3)\n",
              "is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you \n",
              "want to see logs for the training epoch.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            " Training: Medium LR (1e-3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7de0c013d8244762b68e60c972f3258f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /content/lightning_logs/version_1/checkpoints exists and is not empty.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            " Training: High LR (1e-2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "646d3dcbdafb419d85fe1214485055d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n",
            "Test: 10,000 samples\n",
            "\n",
            "==================================================\n",
            " RESULTS SUMMARY:\n",
            "--------------------------------------------------\n",
            "Low LR (1e-4)        ‚Üí Final Loss: 2.3127\n",
            "Medium LR (1e-3)     ‚Üí Final Loss: 0.0000\n",
            "High LR (1e-2)       ‚Üí Final Loss: 0.0000\n",
            "\n",
            " Key Insights:\n",
            "1. Higher learning rates converge faster initially\n",
            "2. Very low learning rates need more time to converge\n",
            "3. Medium LR (1e-3) is usually a good starting point\n",
            "4. Use fast_dev_run to quickly test different LRs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Visualization (CPU)"
      ],
      "metadata": {
        "id": "VIBRfjf3C9pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create fresh model for visualization\n",
        "model_viz = LitCIFAR(learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "opc0PmWQCFaT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for visualization - ON CPU\n",
        "trainer_viz = Trainer(\n",
        "    accelerator='cpu',           # Explicitly use CPU\n",
        "    max_epochs=2,               # 2 epochs for better visualization\n",
        "    limit_train_batches=50,      # 50 batches for meaningful trend\n",
        "    limit_val_batches=20,        # 20 validation batches\n",
        "    log_every_n_steps=10,        # Log every 10 steps\n",
        "    enable_progress_bar=True,\n",
        "    enable_model_summary=True,   # Show model summary\n",
        "    callbacks=[],               # No callbacks for cleaner output\n",
        ")\n",
        "\n",
        "print(\"\\n Starting CPU training for visualization...\")\n",
        "print(\"   Training for 2 epochs (50 batches per epoch)\")\n",
        "print(\"   Watch the progress bar and metrics update!\")\n",
        "print(\"\\n\" + \"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFtJxGW0CT6U",
        "outputId": "8a790bd5-c911-401a-b5f7-3f37f39fee14"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Starting CPU training for visualization...\n",
            "   Training for 2 epochs (50 batches per epoch)\n",
            "   Watch the progress bar and metrics update!\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = trainer_viz.fit(model_viz, data_module)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"CPU Training Complete!\")\n",
        "print(\"\\n What just happened automatically:\")\n",
        "print(\"   ‚úì Training loop executed\")\n",
        "print(\"   ‚úì Validation after each epoch\")\n",
        "print(\"   ‚úì Loss and accuracy logged\")\n",
        "print(\"   ‚úì Progress tracked with ETA\")\n",
        "print(\"   ‚úì All on CPU with zero GPU code!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "efda5c6941e24a968ffabdb82ee4bf6a",
            "73e69cb229e845878dba48075c60e6c9"
          ]
        },
        "id": "bPziKc_TCV0l",
        "outputId": "64abf667-eff3-4cbe-8381-d6a809330fde"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 45,000 samples\n",
            "Validation: 5,000 samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ model     ‚îÇ SimpleCNN          ‚îÇ  545 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ loss_fn   ‚îÇ CrossEntropyLoss   ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ train_acc ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ val_acc   ‚îÇ MulticlassAccuracy ‚îÇ      0 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 545 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 545 K                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 10                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 545 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 545 K                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 10                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efda5c6941e24a968ffabdb82ee4bf6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "CPU Training Complete!\n",
            "\n",
            " What just happened automatically:\n",
            "   ‚úì Training loop executed\n",
            "   ‚úì Validation after each epoch\n",
            "   ‚úì Loss and accuracy logged\n",
            "   ‚úì Progress tracked with ETA\n",
            "   ‚úì All on CPU with zero GPU code!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Check the metrics above:\")\n",
        "print(\"   ‚Ä¢ train_loss: Decreased over time (good!)\")\n",
        "print(\"   ‚Ä¢ train_acc: Increased (learning happening!)\")\n",
        "print(\"   ‚Ä¢ val_loss/val_acc: Model generalizing\")\n",
        "\n",
        "print(\"\\n Try changing these and re-running:\")\n",
        "print(\"   ‚Ä¢ max_epochs=2 ‚Üí max_epochs=5\")\n",
        "print(\"   ‚Ä¢ learning_rate=1e-3 ‚Üí learning_rate=1e-2\")\n",
        "print(\"   ‚Ä¢ Add EarlyStopping callback\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk5LsTAUCa-N",
        "outputId": "893b90b1-47b1-4ff1-e902-49b01dc6f92c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Check the metrics above:\n",
            "   ‚Ä¢ train_loss: Decreased over time (good!)\n",
            "   ‚Ä¢ train_acc: Increased (learning happening!)\n",
            "   ‚Ä¢ val_loss/val_acc: Model generalizing\n",
            "\n",
            " Try changing these and re-running:\n",
            "   ‚Ä¢ max_epochs=2 ‚Üí max_epochs=5\n",
            "   ‚Ä¢ learning_rate=1e-3 ‚Üí learning_rate=1e-2\n",
            "   ‚Ä¢ Add EarlyStopping callback\n"
          ]
        }
      ]
    }
  ]
}